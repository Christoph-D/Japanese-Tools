[general]
default_model = "deepseek-chat"
enable_compiler_explorer = true

[providers.anthropic]
models = [
    { id = "claude-sonnet-4-20250514", short_name = "s", name = "Claude Sonnet 4" }
]

[providers.deepseek]
models = [
    { id = "deepseek-chat", short_name = "d", name = "DeepSeek-V3.1" }
]

[providers.litellm]
endpoint = ""
models = [
    { id = "deepseek/deepseek-chat", short_name = "d", name = "DeepSeek-V3.1" },
    { id = "openrouter/google/gemini-2.5-flash", short_name = "g", name = "Gemini 2.5 Flash" },
    { id = "openrouter/openai/gpt-4o", short_name = "o", name = "GPT-4o" },
    { id = "mistral/mistral-medium-latest", short_name = "m", name = "Mistral Medium" },
    { id = "anthropic/claude-sonnet-4-20250514", short_name = "s", name = "Claude Sonnet 4" }
]

[providers.mistral]
models = [
    { id = "mistral-medium-latest", short_name = "m", name = "Mistral Medium" }
]

[providers.openrouter]
models = [
    { id = "google/gemini-2.5-flash", short_name = "g", name = "Gemini 2.5 Flash" },
    { id = "openai/gpt-4o", short_name = "o", name = "GPT-4o" },
]

[providers.z-ai]
models = [
    { id = "glm-4.5-air", short_name = "z", name = "GLM-4.5-air" },
]

[providers.z-ai-code]
models = [
    { id = "glm-4.5-air", short_name = "c", name = "GLM-4.5-air" },
]

[channels."#example"]
default_model = "mistral/mistral-medium-latest"
temperature = 0.4
system_prompt = """You are a technical AI assistant in the #example channel.
Focus on practical, accurate solutions for Linux system administration and development.
Be concise and precise. Limit responses to {MAX_LINE_LENGTH} characters."""
